{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydough Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import LLMClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider= \"aws\" # This is changeable to Azure or hosted anywhere else, right now it's Bedrock\n",
    "model = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\" # Change the model to Gemini, say it's \"choosable\"\n",
    "client = LLMClient(provider, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydough_code, pydough_df= client.ask(\"Find the 10 customers with the highest balances\") # Can we change to show only the pydough_code here, and not pydough_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the prompt\n",
    "- Knowledge graph is taken from the inputs as part of the prompt\n",
    "- We will add an LLM to \"choose\" the right KG per the question\n",
    "- Use an LLM to explain the prompt in natural language, so it can be edited if needed\n",
    "- If it needs to be edited, then the prompt is resent\n",
    "- Specifically writes the different interpretations of the question being asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pydough code generated: \\n {pydough_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the output PyDough code\n",
    "- Call an LLM to explain the code\n",
    "- If it is incorrect, then it needs to be edited, we can re-send the prompt and get the new PyDough\n",
    "- If the code has key_terms that don't align with the KG, then the LLM sends the error to recreate the PyDough code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 50)\n",
    "print(f\"pydough dataframe: {pydough_df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the SQL output\n",
    "- Shows the error\n",
    "- Use an LLM to explain the error in natural language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow up question\n",
    "- If there is a follow-up question, an LLM checks if the dataframe that PyDough returned contains the relevant information. If not, it uses the PyDough DSL LLM to get a new dataframe. \n",
    "- Otherwise, use an LLM to write Python code, use Pandas accelerated by Bodo Engine, to get the answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aisuite_deepseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
