import streamlit as st
import psutil

# Custom CSS to style the logo in the top-left corner
st.markdown(
    """
    <style>
        .logo-container {
            position: absolute;
            top: 10px;
            left: 10px;
            z-index: 1000; /* Ensures it's always on top */
        }
        .logo-container img {
            width: 150px; /* Adjusts the logo size */
        }
    </style>
    <div class="logo-container">
        <img src="https://awsmp-logos.s3.amazonaws.com/e4ddeded-08ce-43aa-ab95-23adacfbec40/9e8c3b5d7d59ca6f24b8b1ccd841a1c0.png">
    </div>
    """,
    unsafe_allow_html=True
)


# ---------------------- APP HEADER ----------------------
st.title("PyDough LLM Demo")

st.markdown(
    """
    This interactive demo allows you to generate **PyDough queries** from natural language instructions.  
    Simply enter a query for the **TPCH database**, run it, and explore the results using the dropdown below.  

    You can inspect:
    - **Code**: The PyDough query generated by the LLM.
    - **Full Explanation**: A detailed explanation of how the query works.
    - **DataFrame**: The table containing the query results.
    - **Exception**: Stores any errors encountered while executing the query.
    - **Original Question**: The natural language question input by the user.
    - **Base Prompt**: The initial instruction given to the LLM to generate the query.
    - **Cheat Sheet**: A reference guide or example queries to help the LLM structure responses.
    - **Knowledge Graph**: The metadata structure that informs the LLM about available collections and relationships.
    """
)

# ---------------------- QUERY INPUT ----------------------
st.header("Try it Out!")
st.markdown("Enter a natural language query, and let PyDough generate the corresponding query.")

query = st.text_input("Enter your query:", "List all customers from United States") 


if st.button("Run Query"):
    try:
        # Create a new LLMClient instance inside the query execution (fixes SQLite thread issue)
        from llm import LLMClient
        client = LLMClient()  
        
        # Call the LLM client to generate the PyDough query
        result = client.ask(query)
        st.session_state.result = result  # Store only result, not the client

        st.success("Query executed successfully! âœ…")
    except Exception as e:
        st.error(f"Error running query: {e}")

# ---------------------- DISPLAY RESULTS ----------------------
if "result" in st.session_state:
    result = st.session_state.result

    st.markdown('<div class="centered-container">', unsafe_allow_html=True)
    selected_output = st.selectbox(
        "Select what to view:",
        ["Code", "Full Explanation", "DataFrame", "Exception", "Original Question", 
         "Base Prompt", "Cheat Sheet", "Knowledge Graph"],
        key="dropdown",
    )
    st.markdown("</div>", unsafe_allow_html=True)

    # Display the selected part of the result
    if selected_output == "Code":
        st.markdown("Output:")
        st.markdown("---") 
        st.code(result.code, language="python")
    elif selected_output == "Full Explanation":
        st.markdown("Output:")
        st.markdown("---") 
        st.write(result.full_explanation)
    elif selected_output == "DataFrame":
        st.markdown("Output:")
        st.markdown("---") 
        if hasattr(result, "df"):
            st.dataframe(result.df)
        else:
            st.write("No dataframe available.")
    elif selected_output == "Exception":
        st.markdown("Output:")
        st.markdown("---") 
        st.write(result.exception)
    elif selected_output == "Original Question":
        st.markdown("Output:")
        st.markdown("---") 
        st.write(result.original_question)
    elif selected_output == "Base Prompt":
        st.markdown("Output:")
        st.markdown("---") 
        st.write(result.base_prompt)
    elif selected_output == "Cheat Sheet":
        st.markdown("Output:")
        st.markdown("---") 
        st.write(result.cheat_sheet)
    elif selected_output == "Knowledge Graph":
        st.markdown("Output:")
        st.markdown("---") 
        st.write(result.knowledge_graph)
