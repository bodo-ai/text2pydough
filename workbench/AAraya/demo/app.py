import streamlit as st
import psutil
from llm import LLMClient

st.image("logo.png", width=150, use_container_width=False)

# ---------------------- APP HEADER ----------------------
st.title("PyDough LLM Demo")

st.markdown(
    """
    This interactive demo allows you to generate **PyDough queries** from natural language instructions.  
    Simply enter a query for the **TPCH database**, run it, and explore the results using the dropdown below.  

    You can inspect:
    - **Code**: The PyDough query generated by the LLM.
    - **Full Explanation**: A detailed explanation of how the query works.
    - **DataFrame**: The table containing the query results.
    - **Exception**: Stores any errors encountered while executing the query.
    - **Original Question**: The natural language question input by the user.
    - **Base Prompt**: The initial instruction given to the LLM to generate the query.
    - **Cheat Sheet**: A reference guide or example queries to help the LLM structure responses.
    - **Knowledge Graph**: The metadata structure that informs the LLM about available collections and relationships.
    """
)

# ---------------------- QUERY INPUT ----------------------
st.header("Try it Out!")
st.markdown("Enter a natural language query, and let PyDough generate the corresponding query.")

query = st.text_input("Enter your query:", "List all customers from United States")

if st.button("Run Query"):
    try:
        client = LLMClient()  
        result = client.ask(query)
        st.session_state.result = result  # Store only result, not the client
        st.success("Query executed successfully! ✅")
    except Exception as e:
        st.error(f"Error running query: {e}")

# ---------------------- DISPLAY RESULTS ----------------------
if "result" in st.session_state:
    result = st.session_state.result

    st.subheader("Output:")
    st.markdown("---")  # Separator for better readability

    selected_output = st.selectbox(
        "Select what to view:",
        ["Code", "Full Explanation", "DataFrame", "SQL", "Exception", 
         "Original Question", "Base Prompt", "Cheat Sheet", "Knowledge Graph"],  
        key="dropdown",
    )

    if selected_output == "Code":
        st.code(result.code, language="python")
    elif selected_output == "Full Explanation":
        st.write(result.full_explanation)
    elif selected_output == "DataFrame":
        st.dataframe(result.df) if hasattr(result, "df") else st.write("No dataframe available.")
    elif selected_output == "SQL": 
        st.code(result.sql, language="sql") if hasattr(result, "sql") else st.write("No SQL available.")
    elif selected_output == "Exception":
        st.write(result.exception)
    elif selected_output == "Original Question":
        st.write(result.original_question)
    elif selected_output == "Base Prompt":
        st.write(result.base_prompt)
    elif selected_output == "Cheat Sheet":
        st.write(result.cheat_sheet)
    elif selected_output == "Knowledge Graph":
        st.write(result.knowledge_graph)

    # ---------------------- DISCOURSE FUNCTIONALITY ----------------------
    st.header("Improve Query with Discourse")
    st.markdown(
        """
        You can **refine your query** by adding follow-up information.  
        Each time you run Discourse, it will **update the query with new details**.  
        If you want a completely new query, change it in the first section above.
        """
    )

    follow_up = st.text_input("Add follow-up information to refine the query:")

    if st.button("Run Discourse"):
        if follow_up:
            try:
                client = LLMClient()
                improved_result = client.discourse(result, follow_up)
                st.session_state.improved_result = improved_result
                st.success("Query refined successfully! ✅")
            except Exception as e:
                st.error(f"Error running discourse: {e}")
        else:
            st.warning("Enter follow-up information.")

    # ---------------------- DISPLAY IMPROVED RESULTS ----------------------
    if "improved_result" in st.session_state:
        improved_result = st.session_state.improved_result

        st.subheader("Refined Query Output:")
        st.markdown("---")  # Separator for better readability

        selected_output_improved = st.selectbox(
            "Select what to view (Refined Query):",
            ["Code", "Full Explanation", "DataFrame", "SQL", "Exception"],  
            key="dropdown_improved",
        )

        if selected_output_improved == "Code":
            st.code(improved_result.code, language="python")
        elif selected_output_improved == "Full Explanation":
            st.write(improved_result.full_explanation)
        elif selected_output_improved == "DataFrame":
            st.dataframe(improved_result.df) if hasattr(improved_result, "df") else st.write("No dataframe available.")
        elif selected_output_improved == "SQL": 
            st.code(improved_result.sql, language="sql") if hasattr(improved_result, "sql") else st.write("No SQL available.")
        elif selected_output_improved == "Exception":
            st.write(improved_result.exception)



